2017-07-17 04:47:18.978318: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2017-07-17 04:47:18.978735: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties:
name: GeForce GTX 750 Ti
major: 5 minor: 0 memoryClockRate (GHz) 1.1105
pciBusID 0000:01:00.0
Total memory: 1.95GiB
Free memory: 1.87GiB
2017-07-17 04:47:18.978772: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0
2017-07-17 04:47:18.978869: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y
2017-07-17 04:47:18.978893: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 750 Ti, pci bus id: 0000:01:00.0)
2017-07-17 04:47:28.687019: W tensorflow/core/common_runtime/bfc_allocator.cc:217] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.14GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
2017-07-17 04:47:35.164864: W tensorflow/core/common_runtime/bfc_allocator.cc:217] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.14GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
2017-07-17 04:47:35.296468: W tensorflow/core/common_runtime/bfc_allocator.cc:217] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.12GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.

real    40m6.121s
user    20m37.792s
sys     20m9.700s

